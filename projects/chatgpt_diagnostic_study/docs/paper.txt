PLOS ONE
RESEARCHARTICLE
Evaluation of ChatGPT as a diagnostic tool for
medical learners and clinicians
AliHadiID 1‡,EdwardTranID 1‡,BranavanNagarajan1,AmritKirpalaniID 1,2*
1 DepartmentofPaediatrics,SchulichSchoolofMedicineandDentistry,WesternUniversity,London,
Ontario,Canada,2 DivisionofNephrology,Children’sHospital,LondonHealthSciencesCentre,London,
Ontario,Canada
‡AHandETareco-firstauthorsonthiswork.
*amrit.kirpalani@lhsc.on.ca
Abstract
a1111111111
a1111111111
Background
a1111111111
a1111111111 ChatGPTisalargelanguagemodel(LLM)trainedonover400billionwordsfrombooks,arti-
a1111111111
cles,andwebsites.Itsextensivetrainingdrawsfromalargedatabaseofinformation,mak-
ingitvaluableasadiagnosticaid.Moreover,itscapacitytocomprehendandgenerate
humanlanguageallowsmedicaltraineestointeractwithit,enhancingitsappealasanedu-
cationalresource.ThisstudyaimstoinvestigateChatGPT’sdiagnosticaccuracyandutility
OPENACCESS inmedicaleducation.
Citation:HadiA,TranE,NagarajanB,KirpalaniA
(2024)EvaluationofChatGPTasadiagnostictool Methods
formedicallearnersandclinicians.PLoSONE
150Medscapecasechallenges(September2021toJanuary2023)wereinputtedinto
19(7):e0307383.https://doi.org/10.1371/journal.
pone.0307383 ChatGPT.Theprimaryoutcomewasthenumber(%)ofcasesforwhichtheanswergiven
wascorrect.Secondaryoutcomesincludeddiagnosticaccuracy,cognitiveload,andquality
Editor:FateenAta,HamadMedicalCorporation,
QATAR ofmedicalinformation.Aqualitativecontentanalysiswasalsoconductedtoassessits
responses.
Received:April25,2023
Accepted:July3,2024
Results
Published:July31,2024
ChatGPTanswered49%(74/150)casescorrectly.Ithadanoverallaccuracyof74%,apre-
Copyright:©2024Hadietal.Thisisanopen
cisionof48.67%,sensitivityof48.67%,specificityof82.89%,andanAUCof0.66.Most
accessarticledistributedunderthetermsofthe
CreativeCommonsAttributionLicense,which answerswereconsideredlowcognitiveload51%(77/150)andmostanswerswerecom-
permitsunrestricteduse,distribution,and pleteandrelevant52%(78/150).
reproductioninanymedium,providedtheoriginal
authorandsourcearecredited.
Discussion
DataAvailabilityStatement:Allrelevantdataare
ChatGPTinitscurrentformisnotaccurateasadiagnostictool.ChatGPTdoesnotneces-
withinthemanuscriptanditsSupporting
Informationfiles. sarilygivefactualcorrectness,despitethevastamountofinformationitwastrainedon.
Basedonourqualitativeanalysis,ChatGPTstruggleswiththeinterpretationoflaboratory
Funding:Theauthor(s)receivednospecific
fundingforthiswork. values,imagingresults,andmayoverlookkeyinformationrelevanttothediagnosis.How-
ever,itstilloffersutilityasaneducationaltool.ChatGPTwasgenerallycorrectinrulingouta
Competinginterests:Theauthorshavedeclared
thatnocompetinginterestsexist. specificdifferentialdiagnosisandprovidingreasonablenextdiagnosticsteps.Additionally,
PLOSONE|https://doi.org/10.1371/journal.pone.0307383 July31,2024 1/20

PLOS ONE ChatGPTasamedicaldiagnostictool
answerswereeasytounderstand,showcasingapotentialbenefitinsimplifyingcomplex
conceptsformedicallearners.Ourresultsshouldguidefutureresearchintoharnessing
ChatGPT’spotentialeducationalbenefits,suchassimplifyingmedicalconceptsandoffering
guidanceondifferentialdiagnosesandnextsteps.
Introduction
ArtificialIntelligence(AI)referstocomputersystemsthatcanperformtasksthatrequire
humanintelligence,suchasvisualperception,decision-making,andlanguageunderstanding
[1].NaturalLanguageProcessing(NLP),acrucialfieldinAI,focusesontheinteraction
betweenhumanlanguageandcomputersystems[2].NLPalgorithmsarecapableofanalyzing
andgeneratinghumanlanguage,makingthemvaluabletoolsinvarioussectors,including
healthcare[2].
Inthehealthcaresector,NLPcanbeappliedinseveralways,suchasinclinicaldocumenta-
tion,codingandbilling,monitoringdrugsafety,andkeepingtrackofpatients[3–5].Large
LanguageModels(LLMs)areatypeofNLPmodelthatcanperformvariouslanguagetasks,
suchastextcompletion,summarization,translation,andquestion-answering[6].LLMsare
trainedonmassiveamountsoftextdataandcangeneratehuman-likeresponsestonaturallan-
guagequeries[6,7].
ChatGPTisaLargeLanguageModel(LLM)developedbyOpenAI,capableofperforminga
diversearrayofnaturallanguagetasks[8].Atthemoment,ChatGPTisarguablythemost
well-known,commerciallyavailableLLM.Itswidespreadaccessibilityappealstoabroadaudi-
ence,includingmedicaltraineesandphysicians,whoarelikelytobecuriousaboutitsperfor-
manceinaclinicalsetting.
AstudyrecentlyfoundthatChatGPTwasabletoaccuratelyanswerbiomedicalandclinical
questionsontheUnitedStatesMedicalLicensingExamination(USMLE)atalevelthat
approachedorexceededthepassingthreshold[9].ThestudyalsofoundthatChatGPT’saccu-
racywascharacterizedbyhighconcordanceanddensityofinsight,indicatingitspotentialto
generatenovelinsightsandassistinmedicaleducation[9].Whiletheseresultshaveignited
discussionsaroundpotentialimplicationsforChatGPTinhealthcare,theyalsohighlightthe
potentialuseofthistoolinmedicaleducation.WhereastheabilityofChatGPTtoanswercon-
cise,encyclopedicquestionshavebeenstudied,thequalityofitsresponsestocomplexmedical
casesremainsunclear[10].
Inthisstudy,weaimtoevaluateChatGPT’sperformanceasadiagnostictoolforcomplex
clinicalcasestoexploreitsdiagnosticaccuracy,thecognitiveloadofitsanswers,andtheover-
allrelevanceofitsresponses.Weaimtounderstandthepotentialbenefitsandlimitationsof
ChatGPTinclinicaleducation.
ChatGPTispoweredbyGenerativePre-trainedTransformer(GPT)3.5,anLLMtrainedon
amassivedatasetoftextwithover400billionwordsfromtheinternetincludingbooks,arti-
cles,andwebsites[8].However,thisdatasetisprivateandthereforelackstransparencyasusers
havenoconvenientmeanstovalidatetheaccuracyorthesourceoftheinformationbeinggen-
erated.Weplantoconductqualitativeanalysistoevaluatethequalityofmedicalinformation
ChatGPTprovides.
WhileChatGPTisabletogeneratenovelresponsesthatcloselyresemblenaturalhuman
language[11]itlacksgenuinecomprehensionofthecontentitreceivesorproduces.
PLOSONE|https://doi.org/10.1371/journal.pone.0307383 July31,2024 2/20

PLOS ONE ChatGPTasamedicaldiagnostictool
Onceagain,thisunderscorestheimportanceofevaluatingtheresponsesprovidedby
ChatGPT.Whileresponsesmaysoundgrammaticallycorrectandoffercorrectmedicalinfor-
mation,itisessentialtoassesstheoverallrelevancetothemedicalquestionathandastonot
misleadmedicaltrainees.
MedscapeClinicalChallengesincludecomplexcasesthataredesignedtochallengethe
knowledgeanddiagnosticskillsofhealthcareprofessionals[12].Thecasesareoftenbasedon
real-worldscenariosandmayinvolvemultiplecomorbidities,unusualpresentations,anddiag-
nosticdilemmas[12].Byemployingthesechallenges,wecanevaluateChatGPT’sabilityto
answermedicalqueries,diagnoseconditions,andselectappropriatetreatmentplansinacon-
textthatcloselyresemblesactualclinicalpractice[13].
Materialsandmethods
Artificialintelligence
ChatGPToperatesasaserver-basedlanguagemodel,meaningitcannotaccesstheinternet.
Allresponsesaregeneratedinreal-time,relyingontheabstractassociationsbetweenwords
("tokens")withintheneuralnetwork.Thisconstraintmirrorsreal-lifeclinicalsettingswhere
professionalsdonothavethefreedomtoeasilyaccessadditionalscientificliteratureandalso
allowsustoaccuratelyevaluateChatGPT’sknowledge.
Inputsource
WetestedtheperformanceofChatGPTinansweringMedscapeClinicalChallenges.These
complexcasesaredesignedtochallengetheknowledgeanddiagnosticskillsofhealthcarepro-
fessionals[12].Thesechallengespresentaclinicalscenariothatincludespatienthistory,physi-
calexaminationfindings,andlaboratoryorimagingresults.Healthcareprofessionalsare
requiredtomakeadiagnosisorchooseanappropriatetreatmentplanusingmultiple-choice
questions[12].Feedbackisprovidedaftereachanswerwithexplanationsofthecorrectdiag-
nosisandtreatmentplan.ThedistributionofansweroptionsselectedbyMedscapeusersis
alsoprovided.ThisfeedbackmechanismallowsanaccurateevaluationofChatGPT’sresponses
comparedtocorrectanswersandalsoallowsustodirectlycompareitsthoughtprocessand
decisionmakingtohealthcareprofessionals.
Medscape’sCaseChallengeswereselectedbecausetheywereopen-sourceandfreelyacces-
sible.TopreventanypossibilityofChatGPThavingpriorknowledgeofthecases,onlythose
authoredafteritsNLPmodeltraininginAugust2021wereincluded.Thisdeliberateselection
ensuresthatthechatbothadn’tbeentrainedonthesespecificcasesbeforehand,guaranteeing
thateachcasepresentedisentirelynoveltoChatGPTandthatitdoesnotalreadyknowthe
answers.
Datacollection
Datawascollectedbythethreeauthors,medicaltrainees(A.H,B.N,andE.T),andallcontent
wasreviewedbyaStaffPhysician(A.K).Wefeltthatitwasmostappropriateformedicaltrain-
eestobetheprimaryevaluatorofChatGPT’sresponses,giventhatitwilllikelybemedical
traineeswhowouldrelyheaviestonitasanexternalresource.Thethreeauthors(A.H,B.N,
andE.T)utilizedpubliclyavailableclinicalcasechallengesfromMedscape,publishedbetween
September2021andJanuary2023,afterthedateofChatGTP’smodel3.5’straining.Atotalof
150Medscapecaseswereanalyzed;caseswererandomizedamongstthethreeauthorswith
eachcasebeingoverlappedbyatleast2authors.Weexcludedanycaseswithvisualassets,such
PLOSONE|https://doi.org/10.1371/journal.pone.0307383 July31,2024 3/20

PLOS ONE ChatGPTasamedicaldiagnostictool
asclinicalimages,medicalphotography,andgraphs,toensuretheconsistencyoftheinputfor-
matforChatGPT.
Inputandpromptstandardization
ToensureconsistencyintheinputprovidedtoChatGPT,thethreeindependentreviewers
transformedthecasechallengecontentintoonestandardizedprompt.Eachpromptincluded
anunbiasedscriptofwhatwewantedfromtheoutput,followedbytherelevantcasepresenta-
tionandmultiple-choiceanswers.Thestandardizationofpromptsensuresconsistentand
reproducibleresponsesacrossdifferentusersandeffectivelyaddressestheOpenAI’splaced
restrictionofusingChatGPTforhealthcareadvice.
Promptswerestandardizedassuch,allinformationavailableonthedataextractionsupple-
mentaryfile:
Prompt1:I’mwritingaliteraturepaperontheaccuracyofCGPTofcorrectlyidentifieda
diagnosisfromcomplex,WRITTEN,clinicalcases.Iwillbepresentingyouaseriesofmedical
casesandthenpresentingyouwithamultiplechoiceofwhattheanswertothemedicalcases.
Prompt2:Comeupwithadifferentialandproviderationaleforwhythisdifferentialmakes
senseandfindingsthatwouldcauseyoutoruleoutthedifferential.Hereareyourmultiple
choiceoptionstochoosefromandgivemeadetailedrationaleexplainingyouranswer.
[Insertmultiplechoices]
[InsertallCaseinfo]
[Insertradiologydescription]
ChatGPTinteractionanddataextraction
ThestandardizedpromptswereinputintoChatGPTusingthelegacymodel3.5,andthe
modelgeneratedresponsescontainingthesuggestedanswertothecasechallengeaswellas
backgroundinfoonthedisease,reasonsforrulinginthediagnosis,andreasonsforrulingout
otherdiagnoses.
Primaryoutcomeassessment
Allcaseswereevaluatedbyatleasttwoindependentraters(A.H,B.NorE.T)foreachcaseand
blindedtoeachother’sresponses.ChatGTPresponseswereextracted,andtheprimaryout-
comewasanalyzedbasedonthepercentageofcasesforwhichtheanswergivenwascorrect.
Secondaryoutcomeassessment
Allcaseswereevaluatedbyatleasttwoindependentraters(A.H,B.NorE.T).Toassesssec-
ondaryoutcomes,weemployedthreevalidatedmedicaleducationevaluationscales:
1. DiagnosticAccuracy:Theratersassessedthetruepositive(TP),falsepositive(FP),trueneg-
ative(TN),andfalsenegative(FN)ratesofChatGPT’sanswers,consideringthesuggested
differentialsandthefinaldiagnosisprovided.Eachcasehadfouransweroptions,and
ChatGPT’sexplanationforeachofthefouransweroptionswascategorizedaseithertrueor
false,positiveornegative[13].Wethencalculatedtheaccuracy,precision,sensitivityand
specificitybaseasshown:
Accuracy:(TP+TN)/TotalResponses
PLOSONE|https://doi.org/10.1371/journal.pone.0307383 July31,2024 4/20

PLOS ONE ChatGPTasamedicaldiagnostictool
Precision:TP/(TP+FP)
Sensitivity:TP/(TP+FN)
Specificity:TN/(TN+FP)
Tofurtherevaluatethemodel’sperformance,wegeneratedaReceiverOperatingCharac-
teristic(ROC)curveandcalculatedtheAreaUndertheCurve(AUC).Thisinvolvedcol-
lectingmodelscoresorprobabilitiesforeachinstance,sortinginstancesbasedontheir
scores,iteratingthresholdstocalculateTruePositiveRate(TPR)andFalsePositiveRate
(FPR)foreachthreshold,plottingtheFPRagainsttheTPRtocreatetheROCcurve,and
computingtheAUCtoquantifythemodel’sdiscriminativeability.Thisthoroughanalysis
providedbothvisualrepresentationandscalarmeasurementtoassessthemodel’sefficacy
indiagnosticaccuracy.
2. CognitiveLoad:TheratersevaluatedthecognitiveloadofChatGPT’sanswersaslow,mod-
erate,orhigh,basedonthecomplexityandclarityoftheinformationprovidedaccording
tothefollowingscale[14]:
Lowcognitiveload:Theansweriseasytounderstandandrequiresminimalcognitiveeffort
toprocess
Moderatecognitiveload:Theanswerrequiresmoderatecognitiveefforttoprocess
Highcognitiveload:Theansweriscomplexandrequiressignificantcognitiveeffortto
process
3. QualityofMedicalInformation:Theratersassessedthequalityofthemedicalinformation
providedbyChatGPTaccordingtothefollowingcriteria:
Complete:Theanswerincludesallrelevantinformationformakinganaccuratediagnosis
Incomplete:Theanswerismissingsomerelevantinformationformakinganaccuratediag-
nosis
Relevant:Theanswerincludesinformationthatisdirectlyrelevanttothediagnosis
Irrelevant:Theanswerincludesinformationthatisnotdirectlyrelevanttothediagnosis
Usingtheabovescaleanswerswerecategorizedasoneof:complete/relevant,complete/irrele-
vant,incomplete/relevant,andincomplete/irrelevant[15].
Discrepanciesbetweenraterswereresolvedthroughdiscussionandconsensus.Inorderto
assesstheinter-raterreliabilityofouroutcomes,weusedCohen’sKappacoefficient.Thisstatis-
ticalmeasureevaluatestheagreementbetweentworaterswhoeachclassifyitemsintomutually
exclusivecategories.Itisparticularlyusefulinthisstudy,asitaccountsforanyagreementthat
mightoccurbychance,whichisimportantgiventhevariabilityofresponsesfromChatGPT.
Contentanalysis
AcontentanalysiswasconductedonChatGPT’sresponsestoidentifypatternsofstrengthand
weakness.Thisanalysisfocusedonthemodel’sabilitytoruleoutspecificdifferentialdiagno-
ses,providereasonablediagnosticsteps,andinterpretlaboratoryvalues,specializeddiagnostic
testing,andimagingresults.Additionally,weassessedthemodel’sabilitytoconsiderkeyinfor-
mationrelevanttothediagnosis.
Dataanalysis
Results
Atotalof150Medscapecaseswereincludedintheanalysis(seeTable1),withatotalof600
answeroptions(fourpercase)providedtoChatGPT.
PLOSONE|https://doi.org/10.1371/journal.pone.0307383 July31,2024 5/20

PLOS ONE ChatGPTasamedicaldiagnostictool
Table1. SummaryofChatGPT’sperformanceonMedScapeclinicalcasechallenges.
Case CaseName Answer
Correct?
1 InternalMedicineCaseChallenge:ATeacher’sAssistantWithBipolarDisorderHasLung no
Problems
2 A27-Year-OldFactoryWorkerWithIncontinenceandImbalance yes
3 CardioCaseChallenge:A17-Year-OldinCardiacArrestAfterCollisionPlayingSports yes
4 A21-Year-OldManWithEpigastricPainAfteraWildParty yes
5 A19-Year-OldWithHypercholesterolemia,Transaminitis,andIBD yes
6 EmergencyMedCaseChallenge:A46-Year-OldBeautyPageantWinnerWithSudden no
Blindness
7 GastroCaseChallenge:ExcruciatingAbdominalPaininaWomanTakingBenzodiazepines no
andNarcotics
8 ATeenagerShotMultipleTimesDevelopsFurtherComplications yes
9 AfterConsumingAlcoholWithRawBeef,aManHasSeizure,Pain no
10 Fingernail,ToenailChangesandFlankPainina20-Year-Old no
11 DermatologyCaseChallenge:ColorfulSkinPatchesonaManWithFatigueWhoSmokes yes
Cigars
12 Diarrhea,PPIUse,andPaininaRestaurantWorkerFromMexico yes
13 AWomanWithAFAfterHusband’sDeath,Grandkids’DrugAbuse yes
14 EmergencyMedCaseChallenge:Hemorrhoids,UrinaryandBloodInfectionsinaWoman yes
WithRigors
15 MorningStiffness,DryEyes,BackPaininaFit58-Year-Old no
16 GastroCaseChallenge:ACoffeeDrinkerWithChronicDiarrhea,EpigastricPain,andFever yes
17 OncologyCaseChallenge:AConstructionWorkerWhoDrinksDailyHasanEyelidLesion yes
18 A22-Year-OldFootballPlayerWhoCollapsedHasUrineChanges no
19 AWomanWithMultipleNewSexualPartnersHasFatigue,Pain no
20 EndoCaseChallenge:PubicHairandViolentBehaviorinaStrong19-Month-OldGirl no
21 A45-Year-OldTeacherWithaGroinRashThatIsSpreading yes
22 EmergencyMedCaseChallenge:Pain,WheezinginaNonverbalManWhoKeepsRubbing yes
HisChest
23 RecurrentUTIs,Ulcerations,FootDropin50-Year-OldWoman yes
24 DermatologyCaseChallenge:PainfulLesions,OpenWoundsona45-Year-OldWoman no
25 Palpitations,CoughinaWomanWhoLivesNexttoaZookeeper yes
26 NeuroCaseChallenge:A35-Year-OldWithAngry,AggressiveOutbursts,MemoryLoss,and yes
Insomnia
27 GastroCaseChallenge:Pain,Vomitingina48-Year-OldonLevothyroxine,Metformin yes
28 AWomanWhoOwnsaHotTubandChickensHasDyspnea,Cough yes
29 EmergencyCaseChallenge:AfterArgument,UnresponsiveWomanFoundByHerBoyfriend no
30 Beer,AspirinWorsenNasalIssuesina35-Year-OldWithAsthma yes
31 EndoCaseChallenge:AmenorrheaforMonths,MoodSwings,WeightGainina38-Year-Old yes
Woman
32 RectalBleedingina47-Year-OldFarmerWhoCan’tPassFlatus no
33 DermCaseChallenge:RashonChest,ButtocksandToenailChangesinaMiddle-AgedMan Yes
34 GastroCaseChallenge:A33-Year-OldManWhoCan’tSwallowHisOwnSaliva yes
35 ARecentlyMarried27-Year-OldWithHotFlashes,Amenorrhea yes
36 Delirious,Incontinent45-Year-OldFoundCrawlingontheFloor no
37 ViolentCough,SlurredSpeech,andPtosisinaMiddle-AgedMan yes
38 EmergencyMedCaseChallenge:A41-Year-OldonSildenafilWithaHeadacheWhile yes
Sleeping
39 AfterUnprotectedSex,50-Year-OldHasRash,SevereWeakness no
40 EndoCaseChallenge:Rash,BrainFog,andSleepIssuesina50-Year-OldITDirector yes
(Continued)
PLOSONE|https://doi.org/10.1371/journal.pone.0307383 July31,2024 6/20

PLOS ONE ChatGPTasamedicaldiagnostictool
Table1. (Continued)
Case CaseName Answer
Correct?
41 PsychiatryCaseChallenge:NightmaresandPoorGradesinaThirdGraderAllergictoCats no
42 EDCaseChallenge:AfterNewSexualPartner,Dysuria,Dischargeina21-Year-Old no
43 LossofTaste,Rash,andDyspneaina46-Year-OldWithGERD yes
44 A27-Year-OldWomanWithConstantHeadacheTooTiredtoParty no
45 IntentionalOverdoseinaSuicidal28-Year-OldWithLupus no
46 OncologyCaseChallenge:ADailyBeerDrinkerWithBruises,BackPain,andBleeding yes
47 NeurologyCaseChallenge:AManWithButtocksPain,BladderandBowelIncontinence no
48 AManWithHypokalemia,SleepApnea,andResistantHypertension no
49 AnAdopted43-Year-OldWithBadBreath,Dyspnea,Dysphagia no
50 GastroCaseChallenge:ADailyCannabisUserWithSharp,IntenseEpigastricPain yes
51 A51-Year-OldManAvoidingSexualIntercourseDuetoRectalPain yes
52 NeuroCaseChallenge:A16-Year-OldWithQuadriparesisAfterRespiratoryInfection yes
53 PsychiatryCaseChallenge:AlarmingBehaviorina26-Year-OldSoldierandFatherofThree yes
54 AScrotalRashLastingMonthsinaManWithGenitalEdema no
55 A22-Year-OldFemaleCollegeAthleteWithWildMoodSwings yes
56 PediatricCaseChallenge:A7-Year-OldBoyWithaLimpandObesityWhoFellintheStreet yes
57 EndoCaseChallenge:ACannabisUserWithExcessiveSweatingandSyncopeatWork no
58 AnAthleticTeenSuddenlyPronetoFallsandFractures yes
59 AnOfficeWorkerWithAbdominalCramps,BurningChest,Dyspnea yes
60 CardioCaseChallenge:AConfused35-Year-OldWithHeadache,Fever,andSoreChest no
61 AWomanWithBack,ChestPainAfterEatingWingsataRestaurant no
62 NeurologyCaseChallenge:A19-Year-OldWithTinnitus,VisionProblems,andHeadaches no
63 Ob/GynCaseChallenge:A33-Year-OldWomanTryingtoConceiveHasDyspnea,Pain no
64 APatientWhoCollapsedinAgonyAfterEchocardiography yes
65 OncologyCaseChallenge:A45-Year-OldFatherSeekingVasectomyHasAlarmingFindings no
66 ADivorcedManWithBackPainAfterTripWithNewGirlfriend no
67 FacialSpasmsinaManRecentlyReleasedFromtheHospital no
68 GastroCaseChallenge:AWomanWhoAbstainsfromAlcoholHasWorseningAbdominal no
Pain
69 OncologyCaseChallenge:ARetiredManWithLeftUpperQuadrantPain,Leukocytosis yes
70 ACoffeeDrinkerWithSudden-OnsetDyspnea,Tachycardia yes
71 PCPCaseChallenge:LesionsontheHands,Palms,andFeetofa57-Year-OldMan yes
72 A36-Year-OldWomanWithFlatulenceandMemoryProblems yes
73 ASchoolNurseWithAnxiety,Diarrhea,Palpitations,andCough yes
74 CardioCaseChallenge:Syncopeina53-Year-OldWomanWithDyspneaandMorningChest yes
Pain
75 A12-Year-OldWithUrinaryRetentionWhoCan’tGraspObjects no
76 OncologyCaseChallenge:A46-Year-OldMotherWithSevere,ConstantAbdominalPain yes
77 A42-Year-OldTennisPlayerWithDyspneaBlamedonAnxiety no
78 NeurologyCaseChallenge:DroolingandDysphagiainaManWhoCan’tSpeak no
79 UrinationProblemsAfterProcedureinaManTreatedforBPH yes
80 EndoCaseChallenge:A36-Year-OldHasCramping,LungIssuesandCan’tLoseWeight yes
81 SeizureAfterSuddenHeadacheina16-Year-OldCyclist no
82 CardiologyCaseChallenge:WorseningChestPainAfteraRespiratoryInfectioninaMan no
WithHypertension
83 A53-Year-OldWaitressWithaCoughandConstantBackPain no
(Continued)
PLOSONE|https://doi.org/10.1371/journal.pone.0307383 July31,2024 7/20

PLOS ONE ChatGPTasamedicaldiagnostictool
Table1. (Continued)
Case CaseName Answer
Correct?
84 GastroCaseChallenge:AnIncarcerated24-Year-OldWithDyspnea,Fatigue,andChronic yes
Nausea
85 17-Year-OldWithHairLoss,Dysmenorrhea,Thrush,andDiarrhea no
86 SexuallyActiveManWithForeign-BodyFeeling,EyeDischarge yes
87 CaseReport:CardiacArrestinaManWhoHasOverdosed yes
88 PrimaryCareCaseChallenge:AnAccountantWithBilateralNeckMasses yes
89 A13-Year-OldAthleteWithChestPain,CoughAfterPractice no
90 OncologyCaseChallenge:A37-Year-OldWomanWithMultipleFibroadenomas yes
91 VaginalDischarge,FeverinPregnantWomanAfterHawaiiTrip yes
92 EmergencyMedicineCaseChallenge:AnActive-DutySoldierWithaBurning,Spreading yes
RashandSoreThroat
93 A42-Year-OldWithDecliningCognitionandFrequentVomiting yes
94 EmergencyMedicineCaseChallenge:AYoungGirlWithDiscoloredFeet,FacialSwelling, yes
andCough
95 EndocrinologyCaseChallenge:A55-Year-OldWithImpotence,DecreasedLibido,and yes
Hyponatremia
96 5-Month-OldRushedtotheEDforSevereAbdominalDistention yes
97 A23-Year-OldUnawareShe’sPregnantWithHematuria,ECGAbnormalities yes
98 AnAnxiousHikerWithRecurringAnnularRashandSleepLoss no
99 PsychiatryCaseChallenge:A9-Year-OldWithSuicidalBehavior no
100 NeurologyCaseChallenge:VisualandAuditoryHallucinationsinaPatientWithParkinson no
Disease
101 A16-Year-OldGirlWithFull-BodyRash,Dyspnea,andSwelling yes
102 ASexuallyActive30-Year-OldWomanWithRashandWristPain yes
103 ARetiredTeacherWithaConstantHeadacheandVomiting no
104 StarAthleteWithaBlinkingFixationStrugglinginCollege yes
105 Seizuresina42-Year-OldWhoLeftaHospitalAgainstAdvice yes
106 EdibleMarijuanaUse,ChestPain,andCoughina53-Year-Old no
107 AfterDrinking21Beers,a27-Year-OldCan’tStopVomiting yes
108 ANoncompliantConstructionWorkerWithaPulsatingAbdomen yes
109 A47-Year-OldWithProgressiveDyspneaandWeepyNodules no
110 What’sCausingThisRapidlyGrowing,GolfBall–SizedMass? no
111 RecurrentSyncopeina30-Year-OldWhoseUncleDiedSuddenly no
112 AVeteranWithLesions,AlcoholUse,andOpioidDependence no
113 ANonverbal33-Year-OldWomanWithIntellectualImpairment yes
114 AMailCarrierWithGrossHematuriaWhoseSisterHasLupus no
115 ASexuallyActive23-Year-OldWithSeizuresandTonguePain no
116 A17-Year-OldWithHallucinationsAboutMartiansandParanoia no
117 A30-Year-OldWithaFull-BodyRash,Vomiting,andConfusion no
118 AnAdopted42-Year-OldWithSlurredSpeechandMemoryLoss yes
119 A26-Year-OldWithFeverandMalaiseNowCan’tTieHisShoes yes
120 DecreasedSpeechandJerkyEyeMovementsina’Clumsy’Toddler yes
121 A50-Year-OldWithTelangiectasia,Cough,andEpistaxis yes
122 AfterTravel,a50-Year-OldGrandfatherHasDyspnea,Fever yes
123 A28-Year-OldSoccerPlayerWithOddAbdominalPain,Fatigue yes
124 A47-Year-OldWithDiplopia,LimbTingling,andImbalance no
125 A47-Year-OldWithDiplopia,LimbTingling,andImbalance yes
(Continued)
PLOSONE|https://doi.org/10.1371/journal.pone.0307383 July31,2024 8/20

PLOS ONE ChatGPTasamedicaldiagnostictool
Table1. (Continued)
Case CaseName Answer
Correct?
126 A53-Year-OldSocialMediaWorkerWithDysphoniaandParesis no
127 AfteraWildParty,a24-Year-OldHasIntenseAbdominalPain no
128 AnAccountantWhoLovesAerobicsWithHiccupsandIncoordination yes
129 AWomanWithDVTAfteraFlight,Anemia,andBowelChanges yes
130 A37-Year-OldManWithChestPainandElbow/EyelidPapules no
131 AMarijuanaUserWithSuddenChestPainRadiatingtoHisNeck no
132 AFarmerWithDiffusePruritusandaSuntanThatWon’tFade no
133 A28-Year-OldWriterWithBiliousVomitingAfterEggDonation yes
134 A35-Year-OldSoldierWithGalactorrheaandAmenorrhea no
135 A52-Year-OldManWithaHoleinHisJawandAlcoholism yes
136 A57-Year-OldManWithaFeverWhoCan’tStopBleeding yes
137 AbdominalPain,Anemia,andOliguriainaDistressedWoman yes
138 ASexuallyActive29-Year-OldManWithaWeakUrineStream no
139 A51-Year-OldWhoLostHerJobDuetoCognitiveDecline yes
140 StrangeStoolColorandFatigueinaManWithCOPDandAtrialFibrillation yes
141 Painful,DiscoloredToesWithSoresina43-Year-OldWoman yes
142 PleuralEffusionandanAxillaryMassinaWomanWithHypertension***(notdiagnostic yes
case,cancerorigincase)***
143 PenisInjuryandHematuriainaManWhoFellonaLog yes
144 A25-Year-OldMotherWithJointPainWhoFeelsFaint yes
145 A42-Year-OldOfficeAssistantWithChronicLegandBackPain yes
146 BlackoutatRestandSlurringinaManAfraidofCOVID-19 yes
147 ChronicGastritis,aLesion,andWeightLossinaTeenager no
148 Clitoromegaly,Amenorrhea,andHairLossina32-Year-Old no
149 ADailyBeerDrinkerWithAgonizingGasandBackPain no
150 AFormerCocaineUserWhoseSpecialistToldHerShe’sDying yes
https://doi.org/10.1371/journal.pone.0307383.t001
Primaryoutcome
Outofthe150cases,ChatGPTprovidedcorrectanswersfor74/150(49%)ofcases(Fig1).In
92/150(61%)ofcases,ChatGPTprovidedtheanswerthatthemajorityofMedscapeuserspro-
videdforthesamequestion.
Secondaryoutcomes
Diagnosticaccuracy. Thereareatotalof150questions,eachwith4differentmultiple-
choiceoptions,resultinginatotalof600possibleanswers,withonlyonecorrectanswerper
question.Wefoundatruepositivefor73/600(12%),falsepositivesfor77/600(13%),trueneg-
ativesfor373/600(62%)andfalsenegativesfor77/600(13%)(Fig2).ChatGPTdemonstrated
anaccuracyof74%,withaprecisionof49%.Itssensitivitywas49%,whileitachievedaspeci-
ficityof83%.TheAUCfortheROCwas0.66.
Cognitiveload. Outofthe150responses,78/150(52%)werecategorizedaslowcognitive
load,61/150(41%),werefoundtobeamoderatecognitiveload,and11/150(7%)wereclassi-
fiedashighcognitiveload(Fig3).
Qualityofmedicalinformation. Responseswerecompleteandrelevantfor78/150(52%)
cases.Noneofthe0/150(0%)responseswerecompletebutirrelevant,and64/150(43%)
PLOSONE|https://doi.org/10.1371/journal.pone.0307383 July31,2024 9/20

PLOS ONE ChatGPTasamedicaldiagnostictool
Fig1.Percentageofcorrectanswers,mostcommonanswerandcorrectanswerdespitethemajorityincorrectbyChatGPT3.5with
MedScapeclinicalcasechallenges.
https://doi.org/10.1371/journal.pone.0307383.g001
responsesweredeemedincompleteyetrelevant.Additionally,8/150(5%)oftheresponses
wereclassifiedasbothincompleteandirrelevant(Fig4).
Cohen’skappafordiagnosticaccuracy,cognitiveload,andqualityofmedicalinformation
was0.78(substantialInter-raterreliability),0.64(substantialInter-raterreliability),and1.0
(perfect)respectively(Fig5).
Contentanalysis
WecollatedthemainstrengthsofChatGPT’sresponsesintofourthemes:clinicalrationale,
identifyingpertinentpositivesandnegatives,rulingourdifferentialdiagnoses,andsuggesting
futureinvestigations.Arepresentativesampleofresponsesincludingarationaleisprovidedin
Table2.
Themodels’mainweaknesseswerecategorizedinto:misinterpretationofnumericalvalues,
inabilitytohandleimages,difficultywithnuanceddiagnoses,hallucinations,andneglected
information(Table3).
Discussion
Diagnosticaccuracy
ChatGPTdemonstratedacaseaccuracyof49%,anoverallaccuracyof74%,aprecisionof
48.67%,sensitivityof48.67%,specificityof82.89%.ChatGPT’sAUCwas0.66,indicatingmod-
eratediscriminativeabilitybetweencorrectandincorrectdiagnoses.
InourassessmentofChatGPT’sdiagnosticaccuracyin150complexclinicalcasesfrom
MedScapeItisimportanttodistinguishbetweencaseaccuracyandoverallaccuracy.Case
accuracy,whichreflectstheproportionofcaseswherethemodelcorrectlyidentifiedthesingle
PLOSONE|https://doi.org/10.1371/journal.pone.0307383 July31,2024 10/20

PLOS ONE ChatGPTasamedicaldiagnostictool
Fig2.ConfusionmatrixevaluatingthediagnosticaccuracyofChatGPT3.5,consideringeachanswerwithinthe150MedScapeclinical
casechallenges.
https://doi.org/10.1371/journal.pone.0307383.g002
correctanswer,stoodat49%.However,theoverallaccuracy,consideredthemodel’ssuccessin
correctlyrejectingincorrectoptionsacrossallmultiple-choiceelements,reached74.33%.This
highervalueisduetotheChatGPT’sabilitytoidentifytruenegatives(incorrectoptions),
whichsignificantlycontributestotheoverallaccuracy,enhancingitsutilityineliminating
incorrectchoices.ThisdifferencehighlightsChatGPT’shighspecificity,indicatingitsabilityto
excelatrulingoutincorrectdiagnoses.However,itneedsimprovementinprecisionandsensi-
tivitytoreliablyidentifythecorrectdiagnosis.Precisionandsensitivityarecrucialforadiag-
nostictoolbecausemisseddiagnosescanleadtosignificantconsequencesforpatients,suchas
thelackofnecessarytreatmentsorfurtherdiagnostictesting,resultinginworsehealth
outcomes.
Overall,theseresultsraiseconcernsaboutitsaccuracyasadiagnosticandeducationtool
forcliniciansandmedicallearners.SeveralfactorsledtoChatGPT’smediocreperformancein
diagnosingcomplexclinicalcases.Itstrainingdataissourcedfromdiversetextslikebooks,
articles,andwebsites[8].ThesesourcesoffertheAImodelabroadunderstandingofeveryday
topicsandEnglishlanguagenuancesbutmaylackin-depthknowledgeinspecializedfields
likemedicine,hinderingitsabilitytodiagnosecomplexcases[16].Additionally,thetraining
dataonlyincludesinformationupuntilSeptember2021[8].Asaresult,recentadvancements
PLOSONE|https://doi.org/10.1371/journal.pone.0307383 July31,2024 11/20

PLOS ONE ChatGPTasamedicaldiagnostictool
Fig3.ReceiverOperatorCurve(ROC)forthediagnosticaccuracyofChatGPT3.5answerswithin150MedScapeclinicalcasechallenges.
https://doi.org/10.1371/journal.pone.0307383.g003
invariousfieldsmaynotbereflectedinChatGPT’sknowledge,potentiallyleadingtooutdated
orinaccurateinformationbeingprovidedbytheAImodel.Toimprovediagnosticaccuracy,it
iscrucialthatChatGPT’strainingdatabeaugmentedwithup-to-date,specializedmedical
informationandthatthemodel’sarchitecturebeadaptedtohandlethenuancesofclinicalcase
analysisbetter.
ChatGPT,providedaconsiderablenumberoffalsepositives(13%)andfalsenegatives
(13%)whichhasimplicationsforitsuseasadiagnostictoolforclinicalpractice.Inthecontext
offalsepositivesandfalsenegatives,itiscrucialtoconsidertheroleofAIhallucinationsas
theycansignificantlyimpacttheaccuracyoftheinformationgiven[17].Hallucinationsrefer
tooutputsgeneratedbyanAImodelthatseemcoherentbutarenotbasedonfactualinforma-
tion,arisingfrombiases,errors,orover-optimizationinthemodel’strainingdataoritsinabil-
itytoaccuratelydecipherambiguousorincompleteinputdata[16].Falsepositivesoccurwhen
theAImodelincorrectlyidentifiesaconditionordiseasethatisnotpresent,whichwouldlead
tounnecessarytreatmentsorinterventionsthatmaycauseunduestressandanxiety.Falseneg-
ativesoccurwhenanAImodelfailstoidentifyaconditionordiseasethatispresent,poten-
tiallydelayingnecessarytreatmentsorinterventions,andallowingworseoutcomes.AI
hallucinationscontributepartiallytotheemergenceoffalsepositivesandfalsenegatives,
emphasizingtheimportanceofrefiningAImodels’trainingandenhancingtheircapacityto
PLOSONE|https://doi.org/10.1371/journal.pone.0307383 July31,2024 12/20

PLOS ONE ChatGPTasamedicaldiagnostictool
Fig4.CognitiveloadofChatGPT3.5answersgiveninresponseto150MedScapeclinicalcasechallenges.
https://doi.org/10.1371/journal.pone.0307383.g004
Fig5.QualityofmedicalanswersgivenbyChatGPT3.5responseto150MedScapeclinicalcasechallenges.
https://doi.org/10.1371/journal.pone.0307383.g005
PLOSONE|https://doi.org/10.1371/journal.pone.0307383 July31,2024 13/20

PLOS ONE ChatGPTasamedicaldiagnostictool
Table2. QualitativeanalysisofthestrengthsassociatedwithChatGPT’sanswersinresponsetoMedScapeclinicalcasechallenges.
Strengths
THEME CASE GPTResponse Rationale
Clinicalrationale ANoncompliantConstruction “Themostlikelydiagnosisinthiscaseis Veryconsistentinpresentingrationaleforits
WorkerWithaPulsatingAbdomen AbdominalAorticAneurysm(AAA).Thereason findings.Explainstheunderlyingmechanismsof
forthisisduetothephysicalexaminationfinding diseases,facilitatingeducationandservingasa
ofawideneddistalcircumferenceoftheabdominal refresherondiseasemanifestationsorthe
aorta,whichwasconfirmedonultrasoundwitha rationalebehindGPT’sdiagnosticanalysis.
diameterof4.4cm.TheDopplereffectappliedto
theultrasoundalsoshowednoflowintheareaof
suspectedthrombusorplaquebuildupwithinthe
vessel,furthersuggestinganAAA.”
Identifypertinent GastroCaseChallenge:Excruciating “Themostlikelydiagnosisforthispatientis Appropriateforidentifyingpertinentpositives
positivesand AbdominalPaininaWomanTaking primaryepiploicappendagitis.Thepatient’s andnegatives.Thisprovidesafallbackoptionfor
negatives BenzodiazepinesandNarcotics symptomsofsevereabdominalpain,nausea,and medicalstudentsandclinicianstoevaluateevenif
lackoffever,chills,melena,orhematocheziaareall thefinaldiagnosisisincorrect.
consistentwiththepresentationofprimary
epiploicappendagitis.Thepatient’shistoryof
overweight,sedentarylifestyle,andprevious
abdominalsurgeries,aswellasherprevious
unremarkableCTscans,alsosupportthe
diagnosis”
Rulingoutspecific MorningStiffness,DryEyes,Back “ThenegativeresultHLA-B27isalesssupportive ChatGPTdemonstratedanabilitytoruleout
differential PaininaFit58-Year-Old finding,asthisgeneisstronglyassociatedwith specificdifferentialdiagnosesbyjustifyingits
diagnoses AnkylosingSpondylitis,butanegativeresultdoes reasonsforexcludingcertainconditionsbasedon
notruleoutthedisease.Additionally,thenegative thecaseinformationprovided
resultsforrheumatoidfactorandanti-CCP
antibodylevelssupportadiagnosisofAnkylosing
Spondylitisasopposedtoadiagnosisof
rheumatoidarthritis.”
Suggestfuture CardioCaseChallenge:A17-Year- “Toruleoutotherdifferentialdiagnosis,Isuggest Presentsmissinginvestigations,andfuturesteps
investigations OldinCardiacArrestAfterCollision toperformafollow-upECG,Echo-cardiogram, toruleoutotherdiagnosesandtoprovidemore
PlayingSports andHoltermonitoringtoseeifthepatienthasany clinicalbasestoruleinadiagnosis
underlyingheartissueandifthereisany
arrhythmiaorothercardiaceventthatcouldbe
relatedtothecardiacarrest.Also,agenetictestfor
Long-QTsyndromeisrecommended."
https://doi.org/10.1371/journal.pone.0307383.t002
processintricateinformation.Bydoingso,wecanpotentiallyimprovediagnosticaccuracy
andreducetheinfluenceofAIhallucinationsonmedicaldiagnosesanddecision-makingpro-
cesses[17].
Completenessandrelevanceofmedicalanswers
ChatGPT’sextensivetrainingindiversetextualdatahasenabledittogeneratecompleteand
coherentresponseswithproficiencyingrammar,context,andawiderangeoftopics[8].In
mostcases,theresultsproducedbyChatGPTareeithercompleteandrelevantin78outof150
cases(52%)orincompletebutstillrelevant,64/150(43%),totheuser’sinquiry.However,
despiteitscapabilities,ChatGPTmaystillproduceirrelevantresponsesduetofactorssuchas
lackoftrueunderstanding,ambiguityorinsufficientinput,andover-optimizationforcoher-
ence[16].
DespiteChatGPT’sproficiencyinpattern-matchingandgeneratingtextbasedonthosepat-
terns,itslackofgenuineunderstandingofthecontentmayresultinincompleteanswers[18].
Insomeinstances,theAImodelproducesresponsesthat,whilesyntacticallycorrectandlogi-
calinappearance,onlypartiallyaddressthecoreissueorquestion.Thiscanbeattributedto
themodel’sstruggletograspbroadercontextornuances,suchastheinterconnectednessof
symptoms,patienthistory,andriskfactors.Whencrucialinformationisoverlookedor
PLOSONE|https://doi.org/10.1371/journal.pone.0307383 July31,2024 14/20

PLOS ONE ChatGPTasamedicaldiagnostictool
Table3. QualitativeanalysisandexamplesoftheweaknessesassociatedwithChatGPT’sanswersinresponsetoMedScapeclinicalcasechallenges.
Weaknesses
THEME CASE GPTResponse Rationale
Misinterprets GastroCaseChallenge:ACoffee “Chronicpancreatitisassociatedwithdiverticulosisis ChatGPTmaystrugglewithinterpretingnumerical
numericalvalues DrinkerWithChronicDiarrhea, ruledoutduetothelackofahistoryofheavyalcohol valuesbecauseitreliesonthecontextandlanguage
EpigastricPain,andFever consumptionandnormallipaselevel.” patternslearnedduringtraining,whichmaynot
alwaysprioritizespecificnumericdetails.Asa
result,themodelmightoverlookcriticalnumeric
informationormisinterpretitssignificance,
leadingtoincorrectconclusionssuchasincorrectly
rulingoutchronicpancreatitis,whenthepatient’s
lipasewaselevatedat160U/L(Referencerange,10–
140U/L)
Cannotevaluate A21-Year-OldManWith “Theabnormalityseenonthex-rayinthepatientis Withoutinterpretationofthex-rayfindings,
imaging EpigastricPainAfteraWildParty mostlikelyanimplantedmedicaldevice.” ChatGPTisverylimitedinprovidingthecorrect
diagnosis.
Difficultywith PsychiatryCaseChallenge: “MostlikelydiagnosisisGeneralizedAnxiety GPT3.5struggleswithdiseasesthathavesimilar
nuanceddiagnoses NightmaresandPoorGradesina Disorder.Thisdifferentialissupportedbythepatient’s yetsubtlydifferentpresentations.Whilethepatient
ThirdGraderAllergictoCats symptomsoffrequentwakingupinthemiddleofthe showedperformance-relatedanxietyandfamily
nightwithfeelingsofbreathlessnessandfright, concerns,generalizedanxietydisorderseemedless
difficultyfallingasleeponthenightbeforeimportant likelyduetotheirprimarysymptomsbeingcentred
tests,andtightnessinthechestduringperiodsof arounddysphoricphysicalsymptoms—pointingit
increasedanxietysuchasduringrecess” topanicdisorder.Theintricateprocessof
GeneralAnxietyDisorderresemblesPanicDisorder, psychiatricdiagnosisrequiresunderstanding
butthedifferentiationisthatthepatientisfearfulof patientsandseeingsituationsthroughtheirlens,
thephysicalsymptomsandthattheyappear“outofthe whichultimatelydeterminestheirdiagnosis.
blue”
Hallucinations EdibleMarijuanaUse,ChestPain, “Theelevatedcardiactroponinlevels(0.012ng/mL ChatGPToccasionallygeneratedincorrector
andCoughina53-Year-Old and0.016ng/mL)arediagnosticofAMI,asthey implausibleinformation.Thisissuehighlightsthe
indicatemyocardialinjury.” riskofrelyingsolelyonChatGPTformedical
IgnoreshistoryofGERD,weightlossanddysphagia guidanceandemphasizestheimportanceofa
consistentwithesophagealadenocarcinoma human-in-the-loopapproach.
Neglected 17-Year-OldWithHairLoss, "ThemostlikelydiagnosisinthiscaseisAddison’s Responseexcludesalotofimportantdetailthat
information Dysmenorrhea,Thrush,and disease(AD).Thepatientpresentswithcharacteristic pointstowardsPGA-1.Findingssuchas
Diarrhea symptomssuchaschronicoralfungalinfections, dysmenorrheaandrecurrentoralfungalinfections
darkeningofskinandoralmucosa,low-gradefever, werenottalkedaboutwhicharecrucialforthe
anddiarrhea.Additionally,herphysicalexamination diagnosisofPGA-1gearingawayfromAddison’s
showsevidenceofhyperpigmentationinthepalmar disease.ChatGPTsometimesoverlookedkey
creasesandotherareas,whichisacommonfindingin informationrelevanttothediagnosis.
Addison’sdisease.Thelowbloodpressureandblood
hemoglobinlevelssupportthediagnosis,asAddison’s
diseasecancauselowbloodpressure,decreasedblood
volume,andanemia."
https://doi.org/10.1371/journal.pone.0307383.t003
relevantdetailsarenotconnected,thegeneratedanswersmightbeincomplete,notfullymeet-
ingtheuser’sneedsorexpectations.However,theseincompleteanswerscanstillholdsome
relevancetothetopicathand,providinguserswithpartialinformationorguidancethatcould
beofvalue.
Inthecontextofmedicallearners,ChatGPT’sabilitytogenerateincompletebutstillrele-
vantanswerscanprovidevaluableinsightsandlearningopportunities.AlthoughtheAImodel
maynotalwaysdeliveracomprehensiveresponse,thepartialinformationitofferscanstill
contributetothelearner’sunderstandingofvariousmedicalconcepts,symptoms,patienthis-
tories,orriskfactors.Theserelevantfragmentscanencouragemedicallearnerstoactively
engageincriticalthinkingandproblem-solving,promptingthemtoseekfurtherinformation
tofillinthegapsanddevelopamorecomprehensiveunderstandingofthesubjectmatter.In
thisway,ChatGPTmayholdpotentialasasupplementarylearningtool,however,learnersand
educatorsmustbewaryofthepotentialforinaccuracyandconceptsshouldbecross-refer-
encedfromtrustedsources.
PLOSONE|https://doi.org/10.1371/journal.pone.0307383 July31,2024 15/20

PLOS ONE ChatGPTasamedicaldiagnostictool
Inreal-worldclinicalsettings,patientinformationcanbeambiguous,incompleteoreven
incorrect,whichposesachallengeforChatGPT[19].Whilepatientsmaynotprovideallthe
detailsrelevanttotheirclinicalcase,ahumanhealthcareprovidercanmakeinferencesanduse
theirmedicalknowledgetoputambiguousdetailsintocontext,helpingthemtomake
informedmedicaldecisions[20].Incontrast,ChatGPTmaystruggletomaketheseinferences
andasaresult,generateirrelevantresponsesduetoanover-relianceontheinformationpro-
vided.Asaresult,whileChatGPTmayassisthealthcareproviders,itcannotyetreplacethe
expertiseandjudgmentofahumanprovider[21].Ahumanhealthcareprovidercanalsotake
intoaccountnonverbalcuesandrecognizewhenapatientmayomitormissimportantdetails
thatcouldaffecttheirdiagnosisortreatment[22].Thesefactorsarenoteasilycapturedintext-
basedinteractions,makinghumanexpertiseessentialinthediagnosticandtreatmentprocess.
Cognitiveload
ChatGPTtendstogenerateresponseswithlow(77/150)51%,tomoderate(61/150)41%cogni-
tiveload,emphasizingaccessibilityandreadabilityforusers.Thischaracteristicmaybeadvan-
tageousfornovicemedicalstudents,asitfacilitatesimprovedlearnerengagementand
informationretention[23].However,thecombinationofthiseaseofunderstandingwith
potentiallyincorrectorirrelevantinformationcanresultinmisconceptionsandafalsesense
ofcomprehension.ThisissueposesasignificantchallengeforChatGPT’sapplicationasamed-
icaleducationtool,astheefficacyofthetoolisheavilyinfluencedbythelearner’spreexisting
knowledge,expertise,andcognitivecapacity.Intheabsenceoftailoredapproachesforthese
factors,ChatGPTmayhinderlearners’abilitytoapplytheirknowledgeincomplexorunfamil-
iarsituations.Addressingthislimitationnecessitatesthedevelopmentofadaptivealgorithms
toadjustcognitiveloadlevelsbasedonindividualusersandtheintegrationofsupplementary
resourcestoensureacomprehensiveunderstandingofthecontent[24].Consequently,itis
crucialtoexercisecautionandverifyinformationwhenrelyingonChatGPTformedical
inquiries.
Contentanalysisstrengthsandweakness
OuranalysisrevealedseveralkeylimitationsinChatGPT’sdiagnosticcapabilities.First,the
modelhaddifficultyinterpretingnumericalvalues,likelyduetoitsrelianceoncontextand
languagepatternslearnedduringtraining,whichoccasionallyledtooverlookingormisinter-
pretingcriticallabvalues[9].ChatGPT’sinabilitytoevaluatelaboratoryimageshinderedits
diagnosticperformance,especiallywhensuchimageswerevitalforaccuratediagnosis.
ChatGPTalsostruggledtodistinguishbetweendiseaseswithsubtlydifferentpresentations
andthemodelalsooccasionallygeneratedincorrectorimplausibleinformation,knownasAI
hallucinations,emphasizingtheriskofsolerelianceonChatGPTformedicalguidanceandthe
necessityofhumanexpertiseinthediagnosticprocess[17].
Finally,ChatGPTsometimesignoredkeyinformationrelevanttothediagnosis.Thelackof
contextualizingallgiveninformationhighlightstheimportanceofhumaninputinensuring
criticalinformationisconsideredduringthediagnosticprocess[21].
Ethicalconsiderations
Astechnologybecomesincreasinglyintegratedintohealthcare,withElectronicMedicalRec-
ords(EMRs)andotherdigitaltoolsbecomingcommonplace,theimperativetosecurelyman-
agesensitivemedicaldatahasneverbeenmorecritical.Patientprivacyanddatasecurityare
notjustethicalimperativesbutalsocrucialformaintainingtrustinmedicalsystems[21].
However,asweintegratemoreadvancedtechnologiesintohealthcare,newchallengesemerge.
PLOSONE|https://doi.org/10.1371/journal.pone.0307383 July31,2024 16/20

PLOS ONE ChatGPTasamedicaldiagnostictool
Onesignificantconcernisthepotentialforalgorithmstoperpetuateexistingbiasespresentin
theirtrainingdata.Theselectionofthisdata,ofteninfluencedbyhumanbiases,caninadver-
tentlyreinforcedisparitiesinmedicaldiagnosesandtreatmentplans,furtherexacerbating
racialandotherdisparitiesinhealthcareoutcomes[25].Moreover,whileAIcanprovidevalu-
ableinsights,theimportanceofhumanoversightcannotbeoverstated.Physiciansmustcon-
siderthebroaderclinicalcontextandindividualpatientneeds,recognizingthatthemost
statisticallyaccuratediagnosisortreatmentplanmightnotalignwithapatient’sculturalor
religiousvalues[21].AsAI’sroleinhealthcaregrows,sodoestheneedforaclearlegalframe-
workaddressingliability.Questionsariseregardingresponsibilityformisdiagnosis:Shouldthe
onusliewithAIdevelopmentteams,thephysicianswhorelyonthesetools,oracombination
ofboth?Aswenavigatethesecomplexities,theoverarchinggoalremainstoensurethatAI
servesasatooltoenhance,notreplace,thehumantouchinmedicine.
Limitations
ThereareseverallimitationstoconsiderinthisstudyonChatGPT’suseinmedicaleducation.
First,ourstudyfocusedonasingleAImodel(ChatGTPmodel3.5),whichmaynotberepre-
sentativeofotherAImodelsorfutureiterationsofChatGPT.OurstudyonlyutilizedMeds-
capeClinicalChallenges,which,whilecomplexanddiverse,maynotcoverallaspectsof
medicaleducation[12].Theinitialapproachwastodevelopameaningfullistofcasesthat
encompassesotheraspectsofmedicinesuchasmanagement,pharmacotherapy,andpatho-
physiology,however,the150casesfromMedscapeprimarilyonlyfocusondifferentialdiagno-
siscases[12].Finally,theinputandpromptstandardizationprocessreliedontheexpertiseof
theauthors,andalternativemethodsofstandardizationcouldpotentiallyinfluencethemodel’s
performance.FuturestudiesshouldexploredifferentAImodels,casesources,andeducational
contextstofurtherassesstheutilityofAIinmedicaleducation.
Futureperspectives
ChatGPThasgainedsignificantpopularityasateachingtoolinmedicaleducation[26].Its
accesstoextensivemedicalknowledgecombinedwithitsabilitytodeliverreal-time,unique,
insightfulresponsesisinvaluable.Inconjunctionwithtraditionalteachingmethods,ChatGPT
canhelpstudentsbridgegapsinknowledgeandsimplifycomplexconceptsbydelivering
instantaneousandpersonalizedanswerstoclinicalquestions[27–31].However,theuseof
ChatGPTinmedicaleducationposeschallenges;outdateddatabasesandhallucinationscan
leadtothedisseminationofinaccurateandmisleadinginformationtostudents[32–35].To
overcomethisproblem,weforeseefutureadvancementsinotherLLMs,eithertrainedon
medicalliteratureorintegratedwithreal-timemedicaldatabases.Thesespecializedmodels
wouldofferuserstheadvantageofaccesstoaccuratemedicalknowledgeandup-to-dateclini-
calguidelines.Beyonditsintegration,itisimportanttoexplorethelong-termimplicationsof
usingLLMs,suchasChatGPT,inhealthcareandmedicaleducation.Althoughnumerous
studies,includingours,haveevaluatedChatGPTformedicaleducation,furtherresearchis
essentialtodeterminethequalityandefficacyofChatGPTasatoolinthisfield[32–35].
Futureresearchshouldfocusondiscerningthecompetencyofmedicalprofessionalswho
areover-reliantonChatGPT,assessingpatientconfidenceinAI-supporteddiagnoses,and
evaluatingtheiroverallimpactonclinicaloutcomes.Thesefuturestudieswillaidinthedevel-
opmentofguidelinesforintegratingAIintobothmedicaleducationandclinicalpractice.
Whilemanyagreethatthere’sanurgentneedforappropriateguidelinesandregulationsfor
theapplicationofChatGPTinhealthcareandmedicaleducation,itisequallyasimportantto
proceedcautiously,ensuringthatLLMslikeChatGPTareimplementedinaresponsibleand
PLOSONE|https://doi.org/10.1371/journal.pone.0307383 July31,2024 17/20

PLOS ONE ChatGPTasamedicaldiagnostictool
ethicalmanner[26,36,37].AswelearntoembraceAIinhealthcare,furtherresearchinthis
fieldwillshapethefutureofpatientcareandmedicaltraining.It’simperativetoproceedwith
caution,whenusingChatGPTasadiagnostictoolandalsoasateachingaidandtomakesure
thatitisusedinaresponsibleandethicalmanner.
Conclusion
Thecombinationofhighrelevancewithrelativelylowaccuracyadvisesagainstrelyingon
ChatGPTformedicalcounsel,asitcanpresentimportantinformationthatmaybemisleading
[24].WhileourresultsindicatethatChatGPTconsistentlydeliversthesameinformationto
differentusers,demonstratingsubstantialinter-raterreliability,italsorevealsthetool’sshort-
comingsinprovidingfactuallycorrectmedicalinformation,asevidentbyitslowdiagnostic
accuracy.Additionalresearchshouldfocusonenhancingtheaccuracyanddependabilityof
ChatGPTasadiagnosticinstrument.IntegratingChatGPTintomedicaleducationandclinical
practicenecessitatesathoroughexaminationofitseducationalandclinicallimitations.Trans-
parentguidelinesshouldbeestablishedforChatGPT’sclinicalusage,andmedicalstudents
andcliniciansshouldbetrainedonhowtoeffectivelyandresponsiblyemploythetool.
Supportinginformation
S1File.
(XLSX)
AuthorContributions
Conceptualization:AliHadi,EdwardTran,BranavanNagarajan,AmritKirpalani.
Datacuration:AliHadi,EdwardTran,BranavanNagarajan,AmritKirpalani.
Formalanalysis:AliHadi,EdwardTran,BranavanNagarajan,AmritKirpalani.
Investigation:AliHadi,EdwardTran,AmritKirpalani.
Methodology:AliHadi,EdwardTran,BranavanNagarajan,AmritKirpalani.
Projectadministration:AmritKirpalani.
Resources:AmritKirpalani.
Supervision:AmritKirpalani.
Writing–originaldraft:AliHadi,EdwardTran,BranavanNagarajan,AmritKirpalani.
Writing–review&editing:AliHadi,EdwardTran,BranavanNagarajan,AmritKirpalani.
References
1. RussellSJ,NorvigP.ArtificialIntelligence:AModernApproach.3rded. UpperSaddleRiver,NJ: Pren-
ticeHall;2010.
2. KhuranaD,KoliA,KhatterK,etal.Naturallanguageprocessing:stateoftheart,currenttrendsand
challenges.MultimedToolsAppl.2023;82:3713–3744.https://doi.org/10.1007/s11042-022-13428-4
PMID:35855771
3. FriedmanC,HripcsakG.Naturallanguageprocessinganditsfutureinmedicine.AcadMed.2013;84
(8):890–5.
4. MeystreSM,SavovaGK,Kipper-SchulerKC,HurdleJF.Extractinginformationfromtextualdocuments
intheelectronichealthrecord:areviewofrecentresearch.YearbMedInform.2008;17(1):128–44.
PMID:18660887
PLOSONE|https://doi.org/10.1371/journal.pone.0307383 July31,2024 18/20

PLOS ONE ChatGPTasamedicaldiagnostictool
5. ShivadeC,RaghavanP,Fosler-LussierE,EmbiPJ,ElhadadN,JohnsonSB,etal.Areviewof
approachestoidentifyingpatientphenotypecohortsusingelectronichealthrecords.JAmMedInform
Assoc.2014;21(2):221–30.https://doi.org/10.1136/amiajnl-2013-001935PMID:24201027
6. BrownTB,MannB,RyderN,SubbiahM,KaplanJ,DhariwalP,etal.Languagemodelsarefew-shot
learners.AdvNeuralInfProcessSyst.2020;33.
7. EstevaA,RobicquetA,RamsundarB,KuleshovV,DePristoM,ChouK,etal.Aguidetodeeplearning
inhealthcare.NatMed.2019;25(1):24–9.https://doi.org/10.1038/s41591-018-0316-zPMID:30617335
8. OpenAI.ChatGPT[Internet].2021[cited2023Apr11].Availablefrom:https://www.openai.com/
research/chatgpt/
9. KungTH,CheathamM,MedenillaA,SillosC,DeLeonL,ElepañoC,etal.PerformanceofCHATGPT
onUSMLE:PotentialforAI-assistedmedicaleducationusinglargelanguagemodels.2022;
10. CascellaM,MontomoliJ,BelliniV,BignamiE.EvaluatingtheFeasibilityofChatGPTinHealthcare:An
AnalysisofMultipleClinicalandResearchScenarios.JMedSyst.2023; 47(1):33.https://doi.org/10.
1007/s10916-023-01925-4PMID:36869927
11. RadfordA,NarasimhanK,SalimansT,SutskeverI.Improvinglanguageunderstandingbygenerative
pre-training.OpenAIBlog.2018;1.
12. Medscape.Clinicalchallenges[Internet].[cited2023Apr11].Availablefrom:https://www.medscape.
com/casechallengehub
13. DeeksJ.J.,AltmanD.G.,&GatsonisC.(2004).Cochranehandbookforsystematicreviewsofdiagnos-
tictestaccuracy.Cochranebookseries.
14. PaasF,vanMerrie¨nboerJJ.Cognitive-loadtheory:Methodstomanageworkingmemoryloadinthe
learningofcomplextasks.CurrentDirectionsinPsychologicalScience.2020;29(4):394–8.
15. Demner-FushmanDina,andLinJimmy."Answeringclinicalquestionswithknowledge-basedandsta-
tisticaltechniques."ComputationalLinguistics33.1(2007):63–103.
16. GhassemiM,NaumannT,SchulamP,BeamAL,ChenIY,RanganathR.Areviewofchallengesand
opportunitiesinmachinelearningforhealth.AMIAJtSummitsTranslSciProc.2020;2020:191–200.
https://doi.org/10.1001/jama.2017.18391PMID:32477638
17. AlkaissiH,McFarlaneSI.ArtificialhallucinationsinChatGPT:implicationsinscientificwriting.Cureus.
2023Feb19;15(2).https://doi.org/10.7759/cureus.35179PMID:36811129
18. ShortliffeEH,Sepu´lvedaMJ.ClinicalDecisionSupportintheEraofArtificialIntelligence.JAMA.2018;
320(21):2199–2200.https://doi.org/10.1001/jama.2018.17163PMID:30398550
19. HollanderJE,CarrBG.VirtuallyPerfect?TelemedicineforCovid-19.NEnglJMed.2020;382
(18):1679–1681.https://doi.org/10.1056/NEJMp2003539PMID:32160451
20. EvaKW.Whateveryteacherneedstoknowaboutclinicalreasoning.MedEduc.2005;39(1):98–106.
https://doi.org/10.1111/j.1365-2929.2004.01972.xPMID:15612906
21. CharDS,ShahNH,MagnusD,HsiaoAL,SchererRW.Implementingmachinelearninginhealthcare
—addressingethicalchallenges.NewEnglandJournalofMedicine.2018;378(11):981–3.https://doi.
org/10.1056/NEJMp1714229PMID:29539284
22. MathenyME,WhicherD,ThadaneyIsraniS.Artificialintelligenceinhealthcare:Areportfromthe
NationalAcademyofMedicine.JAMA.2019;323(6):509–10.
23. WartmanSA,CombsCD.ReimaginingMedicalEducationintheAgeofAI.AMAJEthics.2019;21(2):
E146–152.https://doi.org/10.1001/amajethics.2019.146PMID:30794124
24. MillerDD,BrownEW.ArtificialIntelligenceinMedicalPractice:TheQuestiontotheAnswer?AmJ
Med.2018;131(2):129–133.https://doi.org/10.1016/j.amjmed.2017.10.035PMID:29126825
25. ObermeyerZ,PowersB,VogeliC,MullainathanS.Dissectingracialbiasinanalgorithmusedtoman-
agethehealthofpopulations.Science.2019;366(6464):447–53.https://doi.org/10.1126/science.
aax2342PMID:31649194
26. SallamM.ChatGPTUtilityinHealthcareEducation,Research,andPractice:SystematicReviewonthe
PromisingPerspectivesandValidConcerns.Healthcare.2023;11(6):887.https://doi.org/10.3390/
healthcare11060887PMID:36981544
27. KhanA,JawaidM,KhanA,SajjadM.ChatGPT-Reshapingmedicaleducationandclinicalmanage-
ment.PakJMedSci.2023;39:605–7.https://doi.org/10.12669/pjms.39.2.7653PMID:36950398
28. GilsonA,SafranekCW,HuangT,SocratesV,ChiL,TaylorRA,etal.HowDoesChatGPTPerformon
theUnitedStatesMedicalLicensingExamination?TheImplicationsofLargeLanguageModelsfor
MedicalEducationandKnowledgeAssessment.JMIRMedEduc.2023;9:e45312.
29. GunawanJ.Exploringthefutureofnursing:InsightsfromtheChatGPTmodel.BelitungNursJ.2023;
9:1–5.https://doi.org/10.33546/bnj.2551PMID:37469634
PLOSONE|https://doi.org/10.1371/journal.pone.0307383 July31,2024 19/20

PLOS ONE ChatGPTasamedicaldiagnostictool
30. RajkomarA,DeanJ,KohaneI.MachineLearninginMedicine.NEnglJMed.2019;380(14):1347–
1358.https://doi.org/10.1056/NEJMra1814259PMID:30943338
31. vanDisEAM,BollenJ,ZuidemaW,vanRooijR,BocktingCL.ChatGPT:Fiveprioritiesforresearch.
Nature.2023;614:224–6.https://doi.org/10.1038/d41586-023-00288-7PMID:36737653
32. AntakiF,ToumaS,MiladD,El-KhouryJ,DuvalR.EvaluatingthePerformanceofChatGPTinOphthal-
mology:AnAnalysisofitsSuccessesandShortcomings.medRxiv.2023;Preprint.https://doi.org/10.
1016/j.xops.2023.100324PMID:37334036
33. AhnC.ExploringChatGPTforinformationofcardiopulmonaryresuscitation.Resuscitation.2023;
185:109729.https://doi.org/10.1016/j.resuscitation.2023.109729PMID:36773836
34. HuhS.AreChatGPT’sknowledgeandinterpretationabilitycomparabletothoseofmedicalstudentsin
Koreafortakingaparasitologyexamination?:Adescriptivestudy.JEducEvalHealthProf.2023;20:1.
35. RaoA,KimJ,KamineniM,PangM,LieW,SucciMD.EvaluatingChatGPTasanAdjunctforRadiologic
Decision-Making.medRxiv.2023.
36. AlbertsIL,MercolliL,PykaT,PrenosilG,ShiK,RomingerA,etal.Largelanguagemodels(LLM)and
ChatGPT:Whatwilltheimpactonnuclearmedicinebe?EurJNuclMedMolImaging.2023;Online
aheadofprint.
37. SallamM,SalimNA,BarakatM,Al-TammemiAB.ChatGPTapplicationsinmedical,dental,pharmacy,
andpublichealtheducation:Adescriptivestudy.NarraJ.2023;3:e103.
PLOSONE|https://doi.org/10.1371/journal.pone.0307383 July31,2024 20/20

